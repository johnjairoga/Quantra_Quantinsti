{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46b32a96",
   "metadata": {
    "id": "46b32a96"
   },
   "source": [
    "# Notebook Instructions\n",
    "\n",
    "1. All the <u>code and data files</u> used in this course are available in the downloadable unit of the <u>last section of this course</u>.\n",
    "2. You can run the notebook document sequentially (one cell at a time) by pressing **Shift + Enter**. \n",
    "3. While a cell is running, a [*] is shown on the left. After the cell is run, the output will appear on the next line.\n",
    "\n",
    "This course is based on specific versions of Python packages. You can find the details of the packages in <a href='https://quantra.quantinsti.com/quantra-notebook' target=\"_blank\" >this manual</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb32a8a0",
   "metadata": {
    "id": "fb32a8a0"
   },
   "source": [
    "##  Implementing Trading with Machine Learning Regression- Part- 2\n",
    "In the previous notebook, we have covered how to import data and create data indicators. We defined dependent and independent variables for linear regression. Part-2 of the below flowchart represents the steps involved in implementing the trading strategy.\n",
    "![image.png](https://d2a032ejo53cab.cloudfront.net/Glossary/bRWziD3a/p2.drawio.png)\n",
    "\n",
    "In this notebook, you will learn the machine learning regression technique. We will implement a linear regression model on Gold ETF that will predict the Day's High and Day's Low given its Day's Open, High, Low and other defined indicators. The key steps are:\n",
    "\n",
    "1. [Import the Data](#import)\n",
    "2. [Preprocess the Data](#preprocess)\n",
    "3. [Grid Search Cross-Validation](#cross)\n",
    "4. [Split Train and Test Data](#split)\n",
    "5. [Predict the High-Low Prices](#prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c92ca44",
   "metadata": {
    "id": "5c92ca44"
   },
   "outputs": [],
   "source": [
    "# Machine learning libraries\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Import the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# For Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-darkgrid')\n",
    "\n",
    "# To ignore unwanted warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67a29a2",
   "metadata": {
    "id": "e67a29a2"
   },
   "source": [
    "<a id='import'></a>\n",
    "## Import the Data\n",
    "\n",
    "The input data is stored in `input_parameters.csv`, which we will import here as `gold_prices` to make prediction using Pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9396590b",
   "metadata": {
    "id": "9396590b",
    "outputId": "ce25e0da-1724-4c57-c70d-a2751f3edd40"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>S_3</th>\n",
       "      <th>S_15</th>\n",
       "      <th>S_60</th>\n",
       "      <th>Corr</th>\n",
       "      <th>Std_U</th>\n",
       "      <th>Std_D</th>\n",
       "      <th>OD</th>\n",
       "      <th>OL</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-04-15</th>\n",
       "      <td>136.000000</td>\n",
       "      <td>136.750000</td>\n",
       "      <td>130.509995</td>\n",
       "      <td>131.309998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>5.490005</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-04-16</th>\n",
       "      <td>134.899994</td>\n",
       "      <td>135.110001</td>\n",
       "      <td>131.759995</td>\n",
       "      <td>132.800003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.210007</td>\n",
       "      <td>3.139999</td>\n",
       "      <td>-1.100006</td>\n",
       "      <td>3.589996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-04-17</th>\n",
       "      <td>133.809998</td>\n",
       "      <td>134.949997</td>\n",
       "      <td>132.320007</td>\n",
       "      <td>132.869995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.139999</td>\n",
       "      <td>1.489991</td>\n",
       "      <td>-1.089996</td>\n",
       "      <td>1.009995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-04-18</th>\n",
       "      <td>134.119995</td>\n",
       "      <td>135.309998</td>\n",
       "      <td>133.619995</td>\n",
       "      <td>134.300003</td>\n",
       "      <td>132.326665</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.190003</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.309997</td>\n",
       "      <td>1.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-04-19</th>\n",
       "      <td>136.000000</td>\n",
       "      <td>136.020004</td>\n",
       "      <td>134.600006</td>\n",
       "      <td>135.470001</td>\n",
       "      <td>133.323334</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.020004</td>\n",
       "      <td>1.399994</td>\n",
       "      <td>1.880005</td>\n",
       "      <td>1.699997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open        High         Low       Close         S_3  S_15  \\\n",
       "Date                                                                           \n",
       "2013-04-15  136.000000  136.750000  130.509995  131.309998         NaN   NaN   \n",
       "2013-04-16  134.899994  135.110001  131.759995  132.800003         NaN   NaN   \n",
       "2013-04-17  133.809998  134.949997  132.320007  132.869995         NaN   NaN   \n",
       "2013-04-18  134.119995  135.309998  133.619995  134.300003  132.326665   NaN   \n",
       "2013-04-19  136.000000  136.020004  134.600006  135.470001  133.323334   NaN   \n",
       "\n",
       "            S_60  Corr     Std_U     Std_D        OD        OL  \n",
       "Date                                                            \n",
       "2013-04-15   NaN   NaN  0.750000  5.490005       NaN       NaN  \n",
       "2013-04-16   NaN   NaN  0.210007  3.139999 -1.100006  3.589996  \n",
       "2013-04-17   NaN   NaN  1.139999  1.489991 -1.089996  1.009995  \n",
       "2013-04-18   NaN   NaN  1.190003  0.500000  0.309997  1.250000  \n",
       "2013-04-19   NaN   NaN  0.020004  1.399994  1.880005  1.699997  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the data\n",
    "gold_prices = pd.read_csv(\n",
    "    '../data_modules/input_parameters.csv', index_col='Date')\n",
    "\n",
    "# Printing the data\n",
    "gold_prices.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d4d674",
   "metadata": {
    "id": "22d4d674"
   },
   "source": [
    "# Checking for NaN Values\n",
    "Here we will for NaN values, then we will drop all the rows having NaN values using `dropna` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a59fceec",
   "metadata": {
    "id": "a59fceec",
    "outputId": "492a9353-5852-412c-8197-a4dd844652e7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Open      0\n",
       "High      0\n",
       "Low       0\n",
       "Close     0\n",
       "S_3       3\n",
       "S_15     15\n",
       "S_60     60\n",
       "Corr     13\n",
       "Std_U     0\n",
       "Std_D     0\n",
       "OD        1\n",
       "OL        1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold_prices.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813bd9de",
   "metadata": {
    "id": "813bd9de"
   },
   "source": [
    "We have 60 NaN values in `S_60`, 15 NaN values in `S_15`,13 NaN values in `S_13` and 3 NaN values in `S_3` etc.Now we will simply drop all the NaN values using `dropna`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef9f775a",
   "metadata": {
    "id": "ef9f775a",
    "outputId": "2c64b70c-dbb7-41fc-e80f-62b03e04b311"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Open     0\n",
       "High     0\n",
       "Low      0\n",
       "Close    0\n",
       "S_3      0\n",
       "S_15     0\n",
       "S_60     0\n",
       "Corr     0\n",
       "Std_U    0\n",
       "Std_D    0\n",
       "OD       0\n",
       "OL       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropping all the NaN values\n",
    "gold_prices.dropna(inplace=True)\n",
    "\n",
    "# Checking for NaN values\n",
    "gold_prices.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191439f7",
   "metadata": {
    "id": "191439f7"
   },
   "source": [
    "Now our dataframe `gold_prices` is free from NaN values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9dcec15",
   "metadata": {
    "id": "e9dcec15"
   },
   "outputs": [],
   "source": [
    "# Independent variables\n",
    "X = gold_prices[['Open', 'S_3', 'S_15', 'S_60', 'OD', 'OL', 'Corr']]\n",
    "\n",
    "# Dependent variable for upward deviation\n",
    "yU = gold_prices['Std_U']\n",
    "\n",
    "# Dependent variable for downward deviation\n",
    "yD = gold_prices['Std_D']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6648cc",
   "metadata": {
    "id": "7a6648cc"
   },
   "source": [
    "<a id='preprocess'></a>\n",
    "## Data Preprocessing\n",
    "Feeding the model with preprocessed data in a machine learning model is essential. Raw data contains many errors, and using such data will result in inconsistent and erroneous results. \n",
    "\n",
    "\n",
    "### Scaling\n",
    "Suppose a feature has a variance of an order of magnitude larger than the other features. In that case, it might dominate the objective function and make the estimator unable to learn from other features correctly. To achieve this, we call the Standard Scaler function.\n",
    "For more details about how scaling works, please refer to [Section 3, Unit 1](https://quantra.quantinsti.com/startCourseDetails?cid=43&section_no=3&unit_no=1&course_type=paid&unit_type=Video)\n",
    "\n",
    "### Linear Regression\n",
    "As discussed in [Section 4, Unit 1](https://quantra.quantinsti.com/startCourseDetails?cid=43&section_no=4&unit_no=1&course_type=paid&unit_type=Video), linear regression uses independent variables to predict a dependent variable using Linear equation. Here we use `X` as independent and `yU`,`yD` as the dependent variable.\n",
    "\n",
    "## Pipeline\n",
    "\n",
    "As explained in [Section 3, Unit 7](https://quantra.quantinsti.com/startCourseDetails?cid=43&section_no=3&unit_no=7&course_type=paid&unit_type=Document) we define a list containing tuples that specify various machine learning tasks given in the order of execution.\n",
    "\n",
    "Specify in the steps a list of (name, transform) tuples. The 'name' is the variable name given to the task, and the 'transform' is the function used to perform the task. Then, sequentially apply a list of transforms specified in steps using the pipeline.\n",
    "\n",
    "Syntax: \n",
    "```python\n",
    "steps = [(name_1,transform_1), (name_2,transform_2),........(name_n,transform_n)]\n",
    "Pipeline(steps)\n",
    "```\n",
    "We are using the following two steps in our pipeline,\n",
    "1. Scaling the data. \n",
    "2. Fitting the data using the linear regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "280dcb67",
   "metadata": {
    "id": "280dcb67"
   },
   "outputs": [],
   "source": [
    "# First we put scaling and then linear regression in the pipeline.\n",
    "steps = [('scaler', StandardScaler()),\n",
    "         ('linear', LinearRegression())]\n",
    "\n",
    "# Defining pipeline\n",
    "pipeline = Pipeline(steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff114257",
   "metadata": {
    "id": "ff114257"
   },
   "source": [
    "## Hyperparameters\n",
    "\n",
    "There are some parameters that the model itself cannot estimate.But we still need to account for them as they play a crucial role in increasing the performance of the system. Such parameters are called hyperparameters. We used intercept but you can add more hyperparameters to tune this algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "643fb02c",
   "metadata": {
    "id": "643fb02c"
   },
   "outputs": [],
   "source": [
    "# Here we are using intercept as hyperparameter\n",
    "parameters = {'linear__fit_intercept': [0, 1]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed078dd",
   "metadata": {
    "id": "0ed078dd"
   },
   "source": [
    "<a id='cross'></a>\n",
    "## Grid Search Cross-Validation\n",
    "As described in [Section 3, unit 14](https://quantra.quantinsti.com/startCourseDetails?cid=43&section_no=3&unit_no=14&course_type=paid&unit_type=Video), cross-validation indicates the model’s performance in a practical situation. It is used to tackle the overfitting of a model. We will use the `GridSearchCV` function, an inbuilt function for cross-validation.\n",
    "\n",
    "We have set `cv=5`, which implies that the grid search will consider five rounds of cross-validation for averaging the performance results. We are using `GridSearchCV` instead of `RandomSearchCV` due to fewer features.`TimeSeriesSplit` splits training data into multiple segments.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3a96a22",
   "metadata": {
    "id": "f3a96a22"
   },
   "outputs": [],
   "source": [
    "# Using TimeSeriesSplit for cross validation\n",
    "my_cv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# Defining reg as variable for GridSearch function containing pipeline, hyperparameters\n",
    "reg = GridSearchCV(pipeline, parameters, cv=my_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c51644",
   "metadata": {
    "id": "a0c51644"
   },
   "source": [
    "<a id='split'></a>\n",
    "## Split Train and Test Data\n",
    "\n",
    "Now, we will split data into train and test data sets. \n",
    "\n",
    "1. First, 70% of data is used for training and the remaining data for testing.\n",
    "2. Fit the training data to a grid search function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf9423ec",
   "metadata": {
    "id": "cf9423ec"
   },
   "outputs": [],
   "source": [
    "spilitting_ratio = .70\n",
    "\n",
    "# Splitting the data into two parts\n",
    "# Using int to make sure integer number comes out.\n",
    "split = int(spilitting_ratio*len(gold_prices))\n",
    "\n",
    "# Defining train dataset\n",
    "X_train = X[:split]\n",
    "yU_train = yU[:split]\n",
    "yD_train = yD[:split]\n",
    "\n",
    "# Defining test data\n",
    "X_test = X[split:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a16ddf",
   "metadata": {
    "id": "02a16ddf"
   },
   "source": [
    "<a id='prediction'></a>\n",
    "## Prediction\n",
    "\n",
    "We will fit the linear regression model on the training dataset and predict the upward deviation in the test dataset. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f853cbd4",
   "metadata": {
    "id": "f853cbd4",
    "outputId": "cfb8be95-d522-4ce0-8680-df140738116a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None),\n",
       "             estimator=Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                                       ('linear', LinearRegression())]),\n",
       "             param_grid={'linear__fit_intercept': [0, 1]})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "reg.fit(X_train, yU_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8a79fe",
   "metadata": {
    "id": "0e8a79fe"
   },
   "source": [
    "After fitting the data, we will pass the `best_params_` to the `reg` model.`best_params_` is a boolean parameter that can only take 0 or 1 as its value, indicating False or True, respectively. It provides us with information regarding the best linear fit intercept for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3926a786",
   "metadata": {
    "id": "3926a786",
    "outputId": "e2927385-2d89-480d-8a0e-347c1949de2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'linear__fit_intercept': 1}\n"
     ]
    }
   ],
   "source": [
    "# Print best parameter\n",
    "print(reg.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35465ef0",
   "metadata": {
    "id": "35465ef0"
   },
   "source": [
    "We can see `best_params_` for our model gives `linear_fit_intercept` equal to one.\n",
    "\n",
    "Here we predict upward deviation using `reg` model on test dataset. We define `yU_predict` for upward prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24b4804c",
   "metadata": {
    "id": "24b4804c"
   },
   "outputs": [],
   "source": [
    "# Predict the upward deviation\n",
    "yU_predict = reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a68409f",
   "metadata": {
    "id": "6a68409f"
   },
   "source": [
    "Similarly, we will fit the data to predict downward deviation using `X_train` and `yD_train`. Then, we will print `best_params` for the fitted data. After fitting the data, we will predict the downward deviation and assign it to a variable named `yD_predict`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "173bd637",
   "metadata": {
    "id": "173bd637",
    "outputId": "c553d872-a544-4e3b-e4fe-ffc22bb167b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'linear__fit_intercept': 1}\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "reg.fit(X_train, yD_train)\n",
    "\n",
    "# Print best parameter\n",
    "print(reg.best_params_)\n",
    "\n",
    "# Predict the downward deviation\n",
    "yD_predict = reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e609181",
   "metadata": {
    "id": "1e609181"
   },
   "source": [
    "Now we will create `yU_predict` and `yD_predict` columns in the `X_test`.Formulas for upward deviation and downward deviation are given by:\n",
    "\n",
    "Upward deviation  = High - Open\n",
    "\n",
    "Downward deviation = Open - Low\n",
    "\n",
    "It is clear from the above two formulas that upward and downward deviation can not be negative. So, we replace negative values with zero.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04a322e3",
   "metadata": {
    "id": "04a322e3"
   },
   "outputs": [],
   "source": [
    "# Create new column in X_test\n",
    "X_test['yU_predict'] = yU_predict\n",
    "X_test['yD_predict'] = yD_predict\n",
    "\n",
    "# Assign zero to all the negative predicted values to take into account real life conditions\n",
    "X_test.loc[X_test['yU_predict'] < 0, 'yU_predict'] = 0\n",
    "X_test.loc[X_test['yD_predict'] < 0, 'yD_predict'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65e2ca3",
   "metadata": {
    "id": "c65e2ca3"
   },
   "source": [
    "We will use the predicted upside deviation values to calculate the high price and the predicted downside deviation values to calculate the low price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9546e41",
   "metadata": {
    "id": "e9546e41",
    "outputId": "214c04ee-32af-4e28-9038-d151a5a74c57"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>S_3</th>\n",
       "      <th>S_15</th>\n",
       "      <th>S_60</th>\n",
       "      <th>OD</th>\n",
       "      <th>OL</th>\n",
       "      <th>Corr</th>\n",
       "      <th>yU_predict</th>\n",
       "      <th>yD_predict</th>\n",
       "      <th>P_H</th>\n",
       "      <th>P_L</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-05-08</th>\n",
       "      <td>121.540001</td>\n",
       "      <td>120.890000</td>\n",
       "      <td>120.606668</td>\n",
       "      <td>122.611834</td>\n",
       "      <td>0.520004</td>\n",
       "      <td>0.330002</td>\n",
       "      <td>-0.221595</td>\n",
       "      <td>0.521922</td>\n",
       "      <td>0.538998</td>\n",
       "      <td>122.061923</td>\n",
       "      <td>121.001003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-09</th>\n",
       "      <td>120.959999</td>\n",
       "      <td>120.976667</td>\n",
       "      <td>120.633335</td>\n",
       "      <td>122.567001</td>\n",
       "      <td>-0.580002</td>\n",
       "      <td>0.049995</td>\n",
       "      <td>-0.290695</td>\n",
       "      <td>0.526836</td>\n",
       "      <td>0.536895</td>\n",
       "      <td>121.486835</td>\n",
       "      <td>120.423104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-10</th>\n",
       "      <td>121.410004</td>\n",
       "      <td>121.106667</td>\n",
       "      <td>120.694668</td>\n",
       "      <td>122.522667</td>\n",
       "      <td>0.450005</td>\n",
       "      <td>0.210007</td>\n",
       "      <td>-0.280418</td>\n",
       "      <td>0.534113</td>\n",
       "      <td>0.533184</td>\n",
       "      <td>121.944117</td>\n",
       "      <td>120.876820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-13</th>\n",
       "      <td>122.629997</td>\n",
       "      <td>121.180000</td>\n",
       "      <td>120.765334</td>\n",
       "      <td>122.490334</td>\n",
       "      <td>1.219993</td>\n",
       "      <td>1.199997</td>\n",
       "      <td>0.078028</td>\n",
       "      <td>0.523940</td>\n",
       "      <td>0.544198</td>\n",
       "      <td>123.153937</td>\n",
       "      <td>122.085799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-14</th>\n",
       "      <td>122.599998</td>\n",
       "      <td>121.766665</td>\n",
       "      <td>120.918667</td>\n",
       "      <td>122.467167</td>\n",
       "      <td>-0.029999</td>\n",
       "      <td>-0.070000</td>\n",
       "      <td>0.365089</td>\n",
       "      <td>0.493836</td>\n",
       "      <td>0.550817</td>\n",
       "      <td>123.093834</td>\n",
       "      <td>122.049181</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open         S_3        S_15        S_60        OD  \\\n",
       "Date                                                                   \n",
       "2019-05-08  121.540001  120.890000  120.606668  122.611834  0.520004   \n",
       "2019-05-09  120.959999  120.976667  120.633335  122.567001 -0.580002   \n",
       "2019-05-10  121.410004  121.106667  120.694668  122.522667  0.450005   \n",
       "2019-05-13  122.629997  121.180000  120.765334  122.490334  1.219993   \n",
       "2019-05-14  122.599998  121.766665  120.918667  122.467167 -0.029999   \n",
       "\n",
       "                  OL      Corr  yU_predict  yD_predict         P_H         P_L  \n",
       "Date                                                                            \n",
       "2019-05-08  0.330002 -0.221595    0.521922    0.538998  122.061923  121.001003  \n",
       "2019-05-09  0.049995 -0.290695    0.526836    0.536895  121.486835  120.423104  \n",
       "2019-05-10  0.210007 -0.280418    0.534113    0.533184  121.944117  120.876820  \n",
       "2019-05-13  1.199997  0.078028    0.523940    0.544198  123.153937  122.085799  \n",
       "2019-05-14 -0.070000  0.365089    0.493836    0.550817  123.093834  122.049181  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add open values in ['yU_predict'] to get the predicted high column\n",
    "X_test['P_H'] = X_test['Open']+X_test['yU_predict']\n",
    "\n",
    "# Subtract ['yD_predict'] values in open to get the predicted low column.\n",
    "X_test['P_L'] = X_test['Open']-X_test['yD_predict']\n",
    "\n",
    "# Print tail of gold_prices dataframe\n",
    "X_test.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bdbc6f6",
   "metadata": {
    "id": "3bdbc6f6"
   },
   "source": [
    "Here we add the `Close`, `High`, and `Low` columns from `gold_prices` because we will need all these columns to calculate strategy returns in the following notebook.\n",
    "We are using the split function to get only the test part of the `gold_prices`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a990b7d0",
   "metadata": {
    "id": "a990b7d0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>S_3</th>\n",
       "      <th>S_15</th>\n",
       "      <th>S_60</th>\n",
       "      <th>OD</th>\n",
       "      <th>OL</th>\n",
       "      <th>Corr</th>\n",
       "      <th>yU_predict</th>\n",
       "      <th>yD_predict</th>\n",
       "      <th>P_H</th>\n",
       "      <th>P_L</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-05-08</th>\n",
       "      <td>121.540001</td>\n",
       "      <td>120.890000</td>\n",
       "      <td>120.606668</td>\n",
       "      <td>122.611834</td>\n",
       "      <td>0.520004</td>\n",
       "      <td>0.330002</td>\n",
       "      <td>-0.221595</td>\n",
       "      <td>0.521922</td>\n",
       "      <td>0.538998</td>\n",
       "      <td>122.061923</td>\n",
       "      <td>121.001003</td>\n",
       "      <td>120.910004</td>\n",
       "      <td>121.540001</td>\n",
       "      <td>120.769997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-09</th>\n",
       "      <td>120.959999</td>\n",
       "      <td>120.976667</td>\n",
       "      <td>120.633335</td>\n",
       "      <td>122.567001</td>\n",
       "      <td>-0.580002</td>\n",
       "      <td>0.049995</td>\n",
       "      <td>-0.290695</td>\n",
       "      <td>0.526836</td>\n",
       "      <td>0.536895</td>\n",
       "      <td>121.486835</td>\n",
       "      <td>120.423104</td>\n",
       "      <td>121.199997</td>\n",
       "      <td>121.620003</td>\n",
       "      <td>120.860001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-10</th>\n",
       "      <td>121.410004</td>\n",
       "      <td>121.106667</td>\n",
       "      <td>120.694668</td>\n",
       "      <td>122.522667</td>\n",
       "      <td>0.450005</td>\n",
       "      <td>0.210007</td>\n",
       "      <td>-0.280418</td>\n",
       "      <td>0.534113</td>\n",
       "      <td>0.533184</td>\n",
       "      <td>121.944117</td>\n",
       "      <td>120.876820</td>\n",
       "      <td>121.430000</td>\n",
       "      <td>121.730003</td>\n",
       "      <td>121.300003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-13</th>\n",
       "      <td>122.629997</td>\n",
       "      <td>121.180000</td>\n",
       "      <td>120.765334</td>\n",
       "      <td>122.490334</td>\n",
       "      <td>1.219993</td>\n",
       "      <td>1.199997</td>\n",
       "      <td>0.078028</td>\n",
       "      <td>0.523940</td>\n",
       "      <td>0.544198</td>\n",
       "      <td>123.153937</td>\n",
       "      <td>122.085799</td>\n",
       "      <td>122.669998</td>\n",
       "      <td>122.849998</td>\n",
       "      <td>122.330002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-14</th>\n",
       "      <td>122.599998</td>\n",
       "      <td>121.766665</td>\n",
       "      <td>120.918667</td>\n",
       "      <td>122.467167</td>\n",
       "      <td>-0.029999</td>\n",
       "      <td>-0.070000</td>\n",
       "      <td>0.365089</td>\n",
       "      <td>0.493836</td>\n",
       "      <td>0.550817</td>\n",
       "      <td>123.093834</td>\n",
       "      <td>122.049181</td>\n",
       "      <td>122.459999</td>\n",
       "      <td>122.660004</td>\n",
       "      <td>122.120003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open         S_3        S_15        S_60        OD  \\\n",
       "Date                                                                   \n",
       "2019-05-08  121.540001  120.890000  120.606668  122.611834  0.520004   \n",
       "2019-05-09  120.959999  120.976667  120.633335  122.567001 -0.580002   \n",
       "2019-05-10  121.410004  121.106667  120.694668  122.522667  0.450005   \n",
       "2019-05-13  122.629997  121.180000  120.765334  122.490334  1.219993   \n",
       "2019-05-14  122.599998  121.766665  120.918667  122.467167 -0.029999   \n",
       "\n",
       "                  OL      Corr  yU_predict  yD_predict         P_H  \\\n",
       "Date                                                                 \n",
       "2019-05-08  0.330002 -0.221595    0.521922    0.538998  122.061923   \n",
       "2019-05-09  0.049995 -0.290695    0.526836    0.536895  121.486835   \n",
       "2019-05-10  0.210007 -0.280418    0.534113    0.533184  121.944117   \n",
       "2019-05-13  1.199997  0.078028    0.523940    0.544198  123.153937   \n",
       "2019-05-14 -0.070000  0.365089    0.493836    0.550817  123.093834   \n",
       "\n",
       "                   P_L       Close        High         Low  \n",
       "Date                                                        \n",
       "2019-05-08  121.001003  120.910004  121.540001  120.769997  \n",
       "2019-05-09  120.423104  121.199997  121.620003  120.860001  \n",
       "2019-05-10  120.876820  121.430000  121.730003  121.300003  \n",
       "2019-05-13  122.085799  122.669998  122.849998  122.330002  \n",
       "2019-05-14  122.049181  122.459999  122.660004  122.120003  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Copy columns from gold_prices to X_test\n",
    "X_test[['Close', 'High', 'Low']] = gold_prices[['Close', 'High', 'Low']][split:]\n",
    "X_test.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4b85fe",
   "metadata": {},
   "source": [
    "## Store the Data into csv\n",
    "Now we will store our test data for strategy analysis by saving our dataframe into a `test_dataset_pred_high_low.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5a3fe9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing the data for the next notebook\n",
    "X_test[['Close', 'High','P_H', 'Low', 'P_L']].to_csv('test_dataset_pred_high_low.csv', index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0707f2",
   "metadata": {
    "id": "7f0707f2"
   },
   "source": [
    " ### Tweak the Code\n",
    " \n",
    "For further practice, you can tweak the code in the following ways:\n",
    "1. Use different data sets: backtest and try out the model on different data sets.\n",
    "2. Features: create your features using different indicators to improve the prediction accuracy.\n",
    "3. Try Random Search for hyperparameters selection and compare the results.\n",
    "\n",
    "## Conclusion\n",
    "In this notebook, we have predicted the High and low values represented by `P_H` and `P_L`, respectively.\n",
    "The next notebook will generate trading signals using the predicted highs and lows. We will also calculate the strategy returns and generate the performance statistics. <br><br>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Data Preprocessing and Prediction.ipynb",
   "provenance": [
    {
     "file_id": "1oE_u21fmFtV9vYYfPBMW3rjuH629d5rw",
     "timestamp": 1644837511413
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "5159781d4911915b18c0fbe8a046748af728f2e0f1da92475ba775542874e153"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
